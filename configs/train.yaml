project_name: toxicity
model_name: distilbert-base-uncased
output_path: experiments
clearml_file: clearml.conf

experiment_name: toxic-classification
experiment_path: ???

dataset_path: dataset
use_cache_csv: True

validation_size: 0.2

training_args:
  learning_rate: 2e-5
  per_device_train_batch_size: 32
  per_device_eval_batch_size: 32
  num_train_epochs: 40
  weight_decay: 0.01
  evaluation_strategy: "steps"
  save_strategy: "steps"
  metric_for_best_model: "roc_auc"
  eval_steps: 100
  load_best_model_at_end: True
  report_to: "clearml"

callbacks:
  early_stopping:
    _target_: transformers.EarlyStoppingCallback
    early_stopping_patience: 10